# Stage 01: Thread Index Writing

## 튜토리얼 목표

- 1차원 그리드에서 스레드 인덱스 계산하기
- GPU 메모리 할당 및 해제
- 호스트-디바이스 간 데이터 복사

## 핵심 개념

### 1차원 실행 모델 개요

CUDA 커널은 그리드-블록-스레드 계층으로 구성됩니다. 가장 단순한 형태부터 이해하기 위해 이번 스테이지에서는 단 한 개의 블록만을 활용합니다. 각 스레드는 `threadIdx.x`로 블록 내부 위치를 파악해 자신이 담당할 데이터를 식별합니다. 이러한 구조 덕분에 많은 데이터를 병렬로 처리할 수 있습니다.

### 스레드-요소 매핑

Stage 01에서는 **블록 1개, 스레드 128개** 구성으로 커널을 실행합니다. 각 스레드는 자신의 ID를 이용해 배열 인덱스에 접근할 수 있습니다.

```cpp
int idx = threadIdx.x;
// Do something
```

> 스레드와 요소가 일대일로 매핑될 때는 추가 반복이나 경계 검사가 필요하지 않습니다.

### 디바이스 메모리 수명 주기

GPU에서 데이터를 다룰 때는 일정한 순서를 따릅니다:

1. `cudaMalloc`으로 디바이스 메모리를 확보한다.
2. 호스트 데이터를 `cudaMemcpy`로 전송한다.
3. 커널을 실행해 디바이스 메모리를 갱신한다.
4. 결과를 다시 호스트로 복사한다.
5. 사용이 끝난 메모리는 `cudaFree`로 해제한다.

이 흐름을 지키면 자원 누수를 방지하고 여러 실험을 연속해서 수행할 수 있습니다.

### 호스트-디바이스 데이터 이동

데이터 복사 시에는 방향에 맞는 상수를 지정해야 합니다. 예를 들어, 호스트에서 디바이스로 보낼 때는 `cudaMemcpyHostToDevice`, 반대 방향은 `cudaMemcpyDeviceToHost`를 사용합니다. 복사 크기는 항상 바이트 단위이므로 `count * sizeof(T)` 형태를 유지해야 합니다.

## 실습

### 목표

각 스레드가 자신의 전역 인덱스를 출력 배열에 기록하는 CUDA 커널을 작성합니다. 요소 수는 스레드 수와 동일하므로 `threadIdx.x`를 그대로 사용해 0부터 `elementCount - 1`까지의 값을 채우면 됩니다.

### 단계

1. 커널 인자로 출력 포인터와 요소 수를 정의합니다.
2. `int idx = threadIdx.x;`로 현재 스레드가 담당할 인덱스를 구합니다.
3. 해당 인덱스 위치에 값을 기록하고 결과를 확인합니다.

### 기대 출력

```
Stage 1 thread ID write test passed ✅
```
### 참고

그리드는 한 개만 사용합니다.
