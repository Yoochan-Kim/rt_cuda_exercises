# Stage 06: Tiled Matrix Multiplication with Shared Memory

## 튜토리얼 목표

- Stage 05의 단순 행렬 곱셈이 가지는 한계를 이해한다.
- 공유 메모리(`__shared__`)가 무엇인지, 어떤 범위에서 공유되는지를 학습한다.
- 타일 기반(shared memory) 행렬 곱셈의 기본 구조를 익힌다.

## Stage 05 구현의 한계

Stage 05 커널에서 각 스레드는 결과 행렬의 한 셀을 계산하기 위해 `A[row][k]`와 `B[k][col]` 값을 반복적으로 읽습니다. 이때 읽어오는 위치는 **전역 메모리(global memory)**로, 수백 GB/s 수준의 대역폭을 제공하지만 접근 지연이 매우 큽니다(수백 사이클). 스레드가 같은 값을 여러 번 참조하려면 그때마다 전역 메모리로부터 다시 가져와야 하며, L1/L2 캐시가 도움을 주긴 하지만 모든 패턴을 보장하지 않습니다.

Stage 05 커널의 핵심 루프는 아래와 같습니다:

```cpp
float sum = 0.0f;
for (int k = 0; k < A.width; ++k) {
    float a = A.elements[row * A.width + k];  // 전역 메모리에서 읽음
    float b = B.elements[k * B.width + col];  // 전역 메모리에서 읽음
    sum += a * b;
}
C.elements[row * C.width + col] = sum;
```

타일 하나(`BLOCK_SIZE × BLOCK_SIZE`)를 계산할 때 모든 스레드가 동일한 `k`에 대해 `A[row][k]`와 `B[k][col]` 값을 반복적으로 가져옵니다. 예를 들어 `BLOCK_SIZE=16`이면 한 타일에서 16×16=256개의 스레드가 동시에 실행되고, 각 `k`마다 256회 전역 메모리 접근이 발생합니다. `A[row][k]`는 같은 블록의 다른 스레드에게도 필요한 값인데, shared memory를 사용하지 않으면 매번 전역 메모리에서 다시 읽어야 합니다. 이 중복 접근이 많아질수록 전역 메모리 대역폭이 병목이 됩니다. GPU의 연산 유닛은 매우 빠른데 비해 전역 메모리 접근이 느리기 때문에, 데이터 재사용을 극대화하지 않으면 연산 성능을 충분히 활용할 수 없습니다. 이러한 이유로 공유 메모리를 활용해 자주 사용하는 데이터를 블록 내부에서 재사용하는 전략이 중요합니다.

## 공유 메모리란?

1. **정의와 범위**  
   공유 메모리(`__shared__`)는 GPU 장치 메모리 중 하나로, **스레드 블록 내 모든 스레드가 함께 사용할 수 있는** 작은 SRAM 공간입니다. 각 블록마다 별도의 공유 메모리 공간이 할당되며, 블록이 종료되면 해당 공간도 사라집니다.

2. **왜 빠른가?**  
   공유 메모리는 칩 내부의 전용 메모리(SRAM)로 구현되어 전역 메모리 대비 접근 지연이 매우 낮습니다(수십 사이클 vs. 수백 사이클). 다만 용량이 제한되어 있어(보통 블록당 수십 KB) 자주 재사용되는 데이터를 타일 단위로 캐시하는 용도로 적합합니다.

3. **사용 패턴**  
   공유 메모리는 커널 내부에서 `__shared__` 키워드로 선언합니다. 선언된 배열의 크기는 컴파일 시점에 결정되기도 하고, 동적 공유 메모리를 통해 런타임에 지정할 수도 있습니다. 예를 들어:

   ```cpp
   __shared__ float As[BLOCK_SIZE][BLOCK_SIZE];
   __shared__ float Bs[BLOCK_SIZE][BLOCK_SIZE];
   ```

   각 반복에서 스레드가 전역 메모리에서 요소를 읽어 해당 공유 배열에 저장한 뒤, `__syncthreads()`로 동기화하고 곱셈-누적을 진행합니다.

4. **접근 단위**  
   공유 메모리는 **블록 내 모든 스레드**가 접근할 수 있습니다. 특정 워프나 스레드만 사용할 수도 있지만, 기본적으로 블록 전체가 공유합니다. 공유 메모리 접근은 레지스터처럼 빠르지만 은행(bank) 구조로 되어 있어, 여러 스레드가 동시에 같은 은행을 요청하면 충돌(bank conflict)이 발생할 수 있습니다. Stage 06 기본 실습에서는 2차원 배열을 사용해 자연스럽게 은행 충돌을 피하도록 구성되어 있습니다.

5. **동기화의 중요성**  
   공유 메모리에 데이터를 쓰는 스레드와 읽는 스레드가 섞여 있기 때문에, `__syncthreads()`로 블록 단위 동기화를 반드시 수행해야 합니다. 이 호출은 블록 내 모든 스레드가 해당 지점에 도달할 때까지 기다립니다.

## 타일 기반 행렬 곱셈 개요

1. 결과 행렬 `C`를 `BLOCK_SIZE × BLOCK_SIZE` 타일로 분할하고, 각 블록이 한 타일을 담당합니다.
2. 한 타일을 계산하기 위해 `A`의 행 타일과 `B`의 열 타일을 차례로 불러와 공유 메모리에 저장합니다.
3. 공유 메모리에 적재된 두 타일을 곱해 부분 결과를 누적합니다.
4. 모든 타일을 순회하면 해당 `C` 타일이 완성됩니다.

아래는 한 반복에서 수행되는 흐름입니다:

```cpp
__shared__ float As[BLOCK_SIZE][BLOCK_SIZE];
__shared__ float Bs[BLOCK_SIZE][BLOCK_SIZE];

for (int m = 0; m < (A.width / BLOCK_SIZE); ++m) {
    // 전역 메모리 → 공유 메모리로 타일 적재
    As[row][col] = Aelements[...];
    Bs[row][col] = Belements[...];
    __syncthreads();

    // 타일끼리 곱셈-누적
    for (int e = 0; e < BLOCK_SIZE; ++e) {
        Cvalue += As[row][e] * Bs[e][col];
    }
    __syncthreads();
}

// 결과 저장
SetElement(Csub, row, col, Cvalue);
```

이 구조 덕분에 각 타일은 전역 메모리에서 한 번만 호출되고, 여러 스레드가 공유 메모리에 저장된 값을 재사용할 수 있습니다.

## 실습

### 목표

공유 메모리를 사용한 타일 기반 행렬 곱셈 커널을 완성하여 Stage 05 대비 더 높은 성능을 확인합니다.

### 단계

1. `__shared__` 배열을 선언해 A와 B의 타일을 저장합니다.
2. 각 반복에서 스레드가 전역 메모리에서 공통 타일을 공유 메모리에 적재한 뒤, `__syncthreads()`로 동기화합니다.
3. 공유 메모리에 저장된 값을 사용해 곱셈-누적을 수행하고, 다음 타일을 적재하기 전에 다시 동기화합니다.
4. 타일 반복이 모두 끝나면 누적된 결과를 전역 메모리에 기록합니다.
5. 제공된 타이머로 Stage 05와 Stage 06의 실행 시간을 비교합니다.

### 기대 출력

```
Stage 6 matrix multiplication matches reference ✅

Performance Comparison:
  CPU Time: <cpu-ms> ms
  GPU Time (with shared memory): <gpu-ms> ms
  Speedup vs CPU: <cpu-ms/gpu-ms>x
```

> 시간 값은 실행 환경에 따라 달라집니다. Stage 05 대비 GPU 시간이 줄어든 것을 확인해 보세요.

### 참고

- Stage 06에서는 `matrix_with_stride.h`를 사용해 타일 단위 접근을 단순화했습니다 (`GetSubMatrix`, `GetElement`, `SetElement`).
